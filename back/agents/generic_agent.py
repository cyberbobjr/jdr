"""
GM Agent using PydanticAI for role-playing game session management.
Progressive migration from Haystack to PydanticAI.
"""

from typing import Optional, List, Any
from dotenv import load_dotenv
from pydantic_ai import Agent, ModelMessage

# Load environment variables from .env file
load_dotenv()

from back.config import get_llm_config
from back.models.schema import LLMConfig


class GenericAgent:
    """
    ### GenericAgent
    **Description:** A generic PydanticAI agent for simple generation tasks without session context.
    Handles content generation like names, backgrounds, descriptions.
    """

    agent: Agent

    def __init__(self, llm_config: LLMConfig, system_prompt: str = "") -> None:
        """
        ### __init__
        **Description:** Initialize the generic agent with LLM configuration and system prompt.
        **Parameters:**
        - `llm_config` (LLMConfig): LLM configuration containing api_endpoint, api_key, model.
        - `system_prompt` (str): System prompt for the agent.
        """
        from pydantic_ai.models.openai import OpenAIChatModel
        from pydantic_ai.providers.openai import OpenAIProvider
        provider = OpenAIProvider(
            base_url=llm_config.api_endpoint,
            api_key=llm_config.api_key
        )
        model = OpenAIChatModel(
            model_name=llm_config.model,
            provider=provider
        )
        self.agent = Agent(
            model=model,
            system_prompt=system_prompt
        )

    async def run(self, user_message: str, message_history: Optional[List[ModelMessage]] = None) -> Any:
        """
        ### run
        **Description:** Run the generic agent with user input.
        **Parameters:**
        - `user_message` (str): User's message.
        - `message_history` (Optional[List[ModelMessage]]): Previous messages.
        **Returns:** Agent run result.
        """
        return await self.agent.run(
            user_prompt=user_message,
            message_history=message_history or []
        )

    async def run_stream(self, user_message: str, message_history: Optional[List[ModelMessage]] = None) -> Any:
        """
        ### run_stream
        **Description:** Run the generic agent with streaming support.
        **Parameters:**
        - `user_message` (str): User's message.
        - `message_history` (Optional[List[ModelMessage]]): Previous messages.
        **Returns:** Agent streaming result context manager.
        """
        return self.agent.run_stream(
            user_prompt=user_message,
            message_history=message_history or []
        )


def build_simple_gm_agent() -> Agent:
    """
    ### build_simple_gm_agent
    **Description:** Builds a simple GM agent without session context for generation tasks (name, background, description).
    **Parameters:** None
    **Returns:** Configured PydanticAI agent without session dependencies.
    """
    # Simple system prompt for content generation
    system_prompt = """You are an expert game master in medieval-fantasy role-playing games.
You help create coherent and immersive characters.
Always respond concisely and appropriately to the provided context."""
    
    # Create the agent with DeepSeek configuration
    llm_config = get_llm_config()
    return GenericAgent(llm_config, system_prompt).agent
